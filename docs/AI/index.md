AI安全本身就是个比传统安全本身，更加空中楼阁，低门槛的事。

## 认识AI

AI安全CTF是将人工智能/机器学习安全与CTF竞赛结合的比赛形式，主要考察：

机器学习模型的对抗攻击

模型逆向与提取

数据投毒与后门攻击

AI系统的传统安全漏洞

### 主要题型分类

#### 对抗样本攻击

```text
目标：通过微小扰动欺骗分类器
常见任务：
- 白盒攻击（已知模型参数）
- 黑盒攻击（仅API访问）
- 定向/非定向攻击
```

#### 模型逆向工程

```text
目标：从模型中提取敏感信息
包括：
- 模型窃取/功能提取
- 成员推理攻击
- 属性推理攻击
- 训练数据重构
```

#### 后门攻击

```text
目标：识别或植入模型后门
形式：
- 触发模式识别
- 后门检测与清除
- 模型水印验证
```

#### 传统AI系统漏洞

```text
目标：攻击AI系统部署环境
包括：
- 模型序列化漏洞（Pickle RCE）
- API滥用与越权
- 供应链攻击
- 数据泄露
```

所以做好AI安全的核心无非就2点 你有多会使用LLM，你有多关注AI安全相关的最新竞赛和漏洞活动。用他们做产出支撑你的成果经历，再想办法把成果汇总成体系。

在写这个新的新篇章的时候，我也只是按照我的心得去写。
